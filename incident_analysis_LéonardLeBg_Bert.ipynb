{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c65179fa",
   "metadata": {},
   "source": [
    "# *Notebook* à utiliser pour faire le travail pratique # 3 sur l'analyse d'incidents.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel, BertTokenizer\n",
    "from transformers import BertForQuestionAnswering\n",
    "from transformers import BertForMaskedLM, pipeline\n",
    "import json\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from collections import Counter\n",
    "import regex as re\n",
    "import string\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargements Modèles et Tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "2233dd04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForQuestionAnswering: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['qa_outputs.weight', 'qa_outputs.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device : cuda\n"
     ]
    }
   ],
   "source": [
    "# Charger les modèle / Tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "model_mask = BertForMaskedLM.from_pretrained('bert-base-cased')\n",
    "fill_mask = pipeline(\"fill-mask\", model=model_mask, tokenizer=tokenizer)\n",
    "model_answer = BertForQuestionAnswering.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Vérification de la disponibilité du GPU\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Device : {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "a5233392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('This is a description of an incident :  At around 10:00 p.m. on November 10  2013  Employee #1  with Villager  Construction Inc.  with a coworker  were using an asphalt milling machine  (Wirtgen; Model Number: W2100) to grind out existing asphalt from an  interstate at a railroad bridge overpass. Employee # 1 was standing on the  ground  checking the depth of the cut into the asphalt  using a handheld  pendant attached to the machine. The pedant could stretch out from ten to 15  ft. This allowed Employee #1 to walk back and forth  checking the cut. The  operator was on the top of the milling machine  controlling the operation of  the machine and ensuring that the milling machine and dump truck (driven by a  second coworker  who worked for an independent trucking service) kept a safe  working distance. A different company  Protective Services Inc. (PSI)  was  responsible for the traffic control of the job site and had shut down the  inside lane of a three lane section of the interstate  so that work could be  conducted on that lane. The entire work zone was approximately two miles long   from start to finish. Employee #1 and the operator of the milling machine had  completed milling four sections (eight total passes) of the inside lane at the  bridge overpasses and were waiting for PSI to shut down the center lane. Dual  lane shut down of the inside and center lanes of the interstate was completed  around 9:30 p.m.  and Employee #1 and the milling machine operator milled two  sections (four total passes) of the center lane. Once both sides of the  overpass were milled out  approximately 200 ft on each side  Employee #1 and  the operator of the milling machine moved the milling machine down the  interstate  approximately1 000 ft  to a railroad overpass and began setting up  to mill the center lane sections. The truck driver backed his truck into  position and remained in the truck to move the truck slowly forward as milling  took place. Employee #1 was positioned between the milling machine and the  concrete median dividers  inside the coned off work zone. The lanes of travel  were approximately 12 ft wide  so the milling machine made two passes  since  it can only cut seven ft wide on each section to cover the entire lane.  Employee #1 was standing approximately three ft in the far inside lane on the  ground between milling machine and interior median wall inside of the approved  traffic control set up  and approximately midway up the machine and 17 ft from  the traffic control devices and flow of traffic. The milling machine was  approximately nine ft wide by 50 ft long  while operating. Employee #1 was  guarded by the machine from the flow of traffic. Approximately five to ten  minutes into the first pass  the milling machine operator noticed lights  hitting the reflectors on the inside wall and turned briefly to see a vehicle  coming. The operator thought it was the Project manager coming to check on the  status of the project. Then  the operator realized that the oncoming vehicle  was not equipped with a strobe  as required in work zones. The operator turned  and yelled for Employee # 1 to run for safety  as a Chevrolet Tahoe came down  the inside lane where Employee #1 was standing. The driver of the Tahoe  continued traveling in the far inside lane of the work zone  where Employee #1  was struck and thrown some 100 ft from where he was originally standing. The  vehicle was moving approximately 45 mph per hour. As he was transferred to a  hospital by emergency personnel  Employee #1 was treated for severe trauma   lacerations  fractures  and contusions to the body and head. Employee #1 was  pronounced dead at the hospital. The driver of the vehicle disregarded the  traffic control set up  all warning lights on the rear of the milling machine   and cone spacing of 100 ft. The construction work zone was set up correctly  with all signage  cone spacing  tapering  attenuators  and lighting; all of  the traffic control set up was approved by MUTCD for this type of tr . The event of the incident is [MASK].', ['Employee #1  was struck and thrown'])\n",
      "{'contexte': ' At around 10:00 p.m. on November 10  2013  Employee #1  with Villager  Construction Inc.  with a coworker  were using an asphalt milling machine  (Wirtgen; Model Number: W2100) to grind out existing asphalt from an  interstate at a railroad bridge overpass. Employee # 1 was standing on the  ground  checking the depth of the cut into the asphalt  using a handheld  pendant attached to the machine. The pedant could stretch out from ten to 15  ft. This allowed Employee #1 to walk back and forth  checking the cut. The  operator was on the top of the milling machine  controlling the operation of  the machine and ensuring that the milling machine and dump truck (driven by a  second coworker  who worked for an independent trucking service) kept a safe  working distance. A different company  Protective Services Inc. (PSI)  was  responsible for the traffic control of the job site and had shut down the  inside lane of a three lane section of the interstate  so that work could be  conducted on that lane. The entire work zone was approximately two miles long   from start to finish. Employee #1 and the operator of the milling machine had  completed milling four sections (eight total passes) of the inside lane at the  bridge overpasses and were waiting for PSI to shut down the center lane. Dual  lane shut down of the inside and center lanes of the interstate was completed  around 9:30 p.m.  and Employee #1 and the milling machine operator milled two  sections (four total passes) of the center lane. Once both sides of the  overpass were milled out  approximately 200 ft on each side  Employee #1 and  the operator of the milling machine moved the milling machine down the  interstate  approximately1 000 ft  to a railroad overpass and began setting up  to mill the center lane sections. The truck driver backed his truck into  position and remained in the truck to move the truck slowly forward as milling  took place. Employee #1 was positioned between the milling machine and the  concrete median dividers  inside the coned off work zone. The lanes of travel  were approximately 12 ft wide  so the milling machine made two passes  since  it can only cut seven ft wide on each section to cover the entire lane.  Employee #1 was standing approximately three ft in the far inside lane on the  ground between milling machine and interior median wall inside of the approved  traffic control set up  and approximately midway up the machine and 17 ft from  the traffic control devices and flow of traffic. The milling machine was  approximately nine ft wide by 50 ft long  while operating. Employee #1 was  guarded by the machine from the flow of traffic. Approximately five to ten  minutes into the first pass  the milling machine operator noticed lights  hitting the reflectors on the inside wall and turned briefly to see a vehicle  coming. The operator thought it was the Project manager coming to check on the  status of the project. Then  the operator realized that the oncoming vehicle  was not equipped with a strobe  as required in work zones. The operator turned  and yelled for Employee # 1 to run for safety  as a Chevrolet Tahoe came down  the inside lane where Employee #1 was standing. The driver of the Tahoe  continued traveling in the far inside lane of the work zone  where Employee #1  was struck and thrown some 100 ft from where he was originally standing. The  vehicle was moving approximately 45 mph per hour. As he was transferred to a  hospital by emergency personnel  Employee #1 was treated for severe trauma   lacerations  fractures  and contusions to the body and head. Employee #1 was  pronounced dead at the hospital. The driver of the vehicle disregarded the  traffic control set up  all warning lights on the rear of the milling machine   and cone spacing of 100 ft. The construction work zone was set up correctly  with all signage  cone spacing  tapering  attenuators  and lighting; all of  the traffic control set up was approved by MUTCD for this type of tr ', 'question': 'What is the EVENT in the incident?', 'target': ['Employee #1  was struck and thrown']}\n"
     ]
    }
   ],
   "source": [
    "#load data\n",
    "file_path = 'data/dev_examples.json'\n",
    "with open(file_path, 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "def create_input_data_mask(data):\n",
    "    formatted_data = []\n",
    "\n",
    "    for item in data:\n",
    "        text = item['text']\n",
    "        arguments = item['arguments']\n",
    "\n",
    "        input_text_EVENT = f\"This is a description of an incident : {text}. The event of the incident is [MASK].\"\n",
    "        input_text_ACTIVITY = f\"This is a description of an incident : {text}. The activity of the incident is [MASK].\"\n",
    "        input_text_WHO = f\"This is a description of an incident : {text}. The person concern by the incident is [MASK].\"\n",
    "        input_text_WHERE = f\"This is a description of an incident : {text}. The location of the incident is [MASK].\"\n",
    "        input_text_WHEN = f\"This is a description of an incident : {text}. The incident occur [MASK].\"\n",
    "        input_text_CAUSE = f\"This is a description of an incident : {text}. The incident cause is [MASK].\"\n",
    "        input_text_EQUIPMENT = f\"This is a description of an incident : {text}. The equipement use is [MASK].\"\n",
    "        input_text_INJURY = f\"This is a description of an incident : {text}. The incident injury is [MASK].\"\n",
    "        input_text_INJURED = f\"This is a description of an incident : {text}. The person injured is [MASK].\"\n",
    "        input_text_BODYPARTS = f\"This is a description of an incident : {text}. The body part injured is [MASK].\"\n",
    "        input_text_DEATH = f\"This is a description of an incident : {text}. The person who died is [MASK].\"\n",
    "\n",
    "        formatted_data.append((input_text_EVENT, arguments['EVENT']))\n",
    "        formatted_data.append((input_text_ACTIVITY, arguments['ACTIVITY']))\n",
    "        formatted_data.append((input_text_WHO, arguments['WHO']))\n",
    "        formatted_data.append((input_text_WHERE, arguments['WHERE']))\n",
    "        formatted_data.append((input_text_WHEN, arguments['WHEN']))\n",
    "        formatted_data.append((input_text_CAUSE, arguments['CAUSE']))\n",
    "        formatted_data.append((input_text_EQUIPMENT, arguments['EQUIPMENT']))\n",
    "        formatted_data.append((input_text_INJURY, arguments['INJURY']))\n",
    "        formatted_data.append((input_text_INJURED, arguments['INJURED']))\n",
    "        formatted_data.append((input_text_BODYPARTS, arguments['BODY-PARTS']))\n",
    "        formatted_data.append((input_text_DEATH, arguments['DEATH']))\n",
    "    \n",
    "    return formatted_data\n",
    "\n",
    "def create_input_data_answer(data):\n",
    "    formatted_data = []\n",
    "\n",
    "    for item in data:\n",
    "        text = item['text']\n",
    "        arguments = item['arguments']\n",
    "        \n",
    "        for key, values in arguments.items():\n",
    "            question = f\"What is the {key} in the incident?\"\n",
    "            target_text = values\n",
    "\n",
    "            item = {\n",
    "                'contexte': text,\n",
    "                'question': question,\n",
    "                'target': target_text\n",
    "            }\n",
    "            formatted_data.append(item)\n",
    "                \n",
    "    \n",
    "    return formatted_data\n",
    "\n",
    "# Création des question à donner au modèle\n",
    "dataset_mask = create_input_data_mask(data)\n",
    "dataset_answer = create_input_data_answer(data)\n",
    "\n",
    "print(dataset_mask[0])\n",
    "print(dataset_answer[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fonction d'évaluation des modèles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "a80c8fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calcule du score d'une modèle\n",
    "def normalize_answer(s):\n",
    "    \"\"\"Mettre en minuscule et retirer la ponctuation, des déterminants and les espaces.\"\"\"\n",
    "    def remove_articles(text):\n",
    "        return re.sub(r'\\b(a|an|the)\\b', ' ', text)\n",
    "\n",
    "    def white_space_fix(text):\n",
    "        return ' '.join(text.split())\n",
    "\n",
    "    def remove_punc(text):\n",
    "        exclude = set(string.punctuation)\n",
    "        return ''.join(ch for ch in text if ch not in exclude)\n",
    "\n",
    "    def lower(text):\n",
    "        return text.lower()\n",
    "\n",
    "    return white_space_fix(remove_articles(remove_punc(lower(s))))\n",
    "\n",
    "def f1_score(prediction, ground_truth):\n",
    "    \"\"\"Normalise les 2 textes, trouve ce qu'il y a en comment et estime précision, rappel et F1.\"\"\"\n",
    "    prediction_tokens = normalize_answer(prediction).split()\n",
    "    ground_truth_tokens = normalize_answer(ground_truth).split()\n",
    "    common = Counter(prediction_tokens) & Counter(ground_truth_tokens)\n",
    "    num_same = sum(common.values())\n",
    "    if len(ground_truth_tokens) == 0 or len(prediction_tokens) == 0:\n",
    "        return int(ground_truth_tokens == prediction_tokens)\n",
    "    if num_same == 0:\n",
    "        return 0\n",
    "    precision = 1.0 * num_same / len(prediction_tokens)\n",
    "    recall = 1.0 * num_same / len(ground_truth_tokens)\n",
    "    f1 = (2 * precision * recall) / (precision + recall)\n",
    "    return f1\n",
    "\n",
    "def exact_match_score(prediction, ground_truth): \n",
    "    \"\"\"Vérifie si les 2 textes sont quasi-identiques.\"\"\"\n",
    "    return (normalize_answer(prediction) == normalize_answer(ground_truth))\n",
    "\n",
    "def metric_max_over_ground_truths(metric_fn, prediction, ground_truths):\n",
    "    \"\"\"La fonction princiaple. Important de noter que ground_truths est une liste \n",
    "       parce qu'il peut y avoir plusieurs réponses possibles.\"\"\"\n",
    "    scores_for_ground_truths = []\n",
    "    for ground_truth in ground_truths:\n",
    "        score = metric_fn(prediction, ground_truth)\n",
    "        scores_for_ground_truths.append(score)\n",
    "    return max(scores_for_ground_truths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f740e5bc",
   "metadata": {},
   "source": [
    "# Modèle de maskage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "ceb24f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate the  mask model\n",
    "\n",
    "def evaluate_fill_model(dataset, eval_fn):\n",
    "    for item in dataset:\n",
    "        input = item[0]\n",
    "        target = item[1]\n",
    "\n",
    "        result = fill_mask(input)\n",
    "        print(result[0]['token_str'])\n",
    "        print(result[1]['token_str'])\n",
    "        print(result[2]['token_str'])\n",
    "        break\n",
    "\n",
    "#evaluate_fill_model(dataset_mask, f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64348f5e",
   "metadata": {},
   "source": [
    "# Modèle Question-réponse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "5982566e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SEP] This revue notice that a cat mesure 50cm in average and a human 1 . 70m\n"
     ]
    }
   ],
   "source": [
    "def answer_question(question, context, topN=20):\n",
    "    def get_top_answers(possible_starts, possible_ends, input_ids=20):\n",
    "        answers = []\n",
    "        for start, end in zip(possible_starts, possible_ends):\n",
    "            answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(input_ids[start:end+1]))\n",
    "            answers.append(answer)\n",
    "        return answers \n",
    "\n",
    "    inputs = tokenizer.encode_plus(question, context, add_special_tokens=True, return_tensors=\"pt\")    \n",
    "    input_ids = inputs[\"input_ids\"].tolist()[0]\n",
    "\n",
    "    model_out = model_answer(**inputs)\n",
    "     \n",
    "    answer_start_scores = model_out[\"start_logits\"]\n",
    "    answer_end_scores = model_out[\"end_logits\"]\n",
    "\n",
    "    possible_starts = np.argsort(answer_start_scores.cpu().detach().numpy()).flatten()[::-1][:topN]\n",
    "    possible_ends = np.argsort(answer_end_scores.cpu().detach().numpy()).flatten()[::-1][:topN]\n",
    "    \n",
    "    #get best answer\n",
    "    answer_start = torch.argmax(answer_start_scores)  \n",
    "    # Get the most likely end of answer with the argmax of the score\n",
    "    answer_end = torch.argmax(answer_end_scores) + 1  \n",
    "\n",
    "    answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(input_ids[answer_start:answer_end]))\n",
    "    answers = get_top_answers(possible_starts, possible_ends, input_ids )\n",
    "\n",
    "    return { \"answer\":answer,\"answer_start\":answer_start,\"answer_end\":answer_end,\"input_ids\":input_ids,\n",
    "            \"answer_start_scores\":answer_start_scores,\"answer_end_scores\":answer_end_scores,\"inputs\":inputs,\"answers\":answers,\n",
    "            \"possible_starts\":possible_starts,\"possible_ends\":possible_ends}\n",
    "\n",
    "\n",
    "question = \"A human is smaller or taller than a cat?\"\n",
    "context = \"This revue notice that a cat mesure 50cm in average and a human 1.70m.\"\n",
    "output = answer_question(question, context)\n",
    "\n",
    "print(output['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "ae20e38f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (847 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'contexte': ' At around 10:00 p.m. on November 10  2013  Employee #1  with Villager  Construction Inc.  with a coworker  were using an asphalt milling machine  (Wirtgen; Model Number: W2100) to grind out existing asphalt from an  interstate at a railroad bridge overpass. Employee # 1 was standing on the  ground  checking the depth of the cut into the asphalt  using a handheld  pendant attached to the machine. The pedant could stretch out from ten to 15  ft. This allowed Employee #1 to walk back and forth  checking the cut. The  operator was on the top of the milling machine  controlling the operation of  the machine and ensuring that the milling machine and dump truck (driven by a  second coworker  who worked for an independent trucking service) kept a safe  working distance. A different company  Protective Services Inc. (PSI)  was  responsible for the traffic control of the job site and had shut down the  inside lane of a three lane section of the interstate  so that work could be  conducted on that lane. The entire work zone was approximately two miles long   from start to finish. Employee #1 and the operator of the milling machine had  completed milling four sections (eight total passes) of the inside lane at the  bridge overpasses and were waiting for PSI to shut down the center lane. Dual  lane shut down of the inside and center lanes of the interstate was completed  around 9:30 p.m.  and Employee #1 and the milling machine operator milled two  sections (four total passes) of the center lane. Once both sides of the  overpass were milled out  approximately 200 ft on each side  Employee #1 and  the operator of the milling machine moved the milling machine down the  interstate  approximately1 000 ft  to a railroad overpass and began setting up  to mill the center lane sections. The truck driver backed his truck into  position and remained in the truck to move the truck slowly forward as milling  took place. Employee #1 was positioned between the milling machine and the  concrete median dividers  inside the coned off work zone. The lanes of travel  were approximately 12 ft wide  so the milling machine made two passes  since  it can only cut seven ft wide on each section to cover the entire lane.  Employee #1 was standing approximately three ft in the far inside lane on the  ground between milling machine and interior median wall inside of the approved  traffic control set up  and approximately midway up the machine and 17 ft from  the traffic control devices and flow of traffic. The milling machine was  approximately nine ft wide by 50 ft long  while operating. Employee #1 was  guarded by the machine from the flow of traffic. Approximately five to ten  minutes into the first pass  the milling machine operator noticed lights  hitting the reflectors on the inside wall and turned briefly to see a vehicle  coming. The operator thought it was the Project manager coming to check on the  status of the project. Then  the operator realized that the oncoming vehicle  was not equipped with a strobe  as required in work zones. The operator turned  and yelled for Employee # 1 to run for safety  as a Chevrolet Tahoe came down  the inside lane where Employee #1 was standing. The driver of the Tahoe  continued traveling in the far inside lane of the work zone  where Employee #1  was struck and thrown some 100 ft from where he was originally standing. The  vehicle was moving approximately 45 mph per hour. As he was transferred to a  hospital by emergency personnel  Employee #1 was treated for severe trauma   lacerations  fractures  and contusions to the body and head. Employee #1 was  pronounced dead at the hospital. The driver of the vehicle disregarded the  traffic control set up  all warning lights on the rear of the milling machine   and cone spacing of 100 ft. The construction work zone was set up correctly  with all signage  cone spacing  tapering  attenuators  and lighting; all of  the traffic control set up was approved by MUTCD for this type of tr ', 'question': 'What is the EVENT in the incident?', 'target': ['Employee #1  was struck and thrown']}\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (847) must match the size of tensor b (512) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[106], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[38;5;28mprint\u001b[39m(output)\n\u001b[0;32m     10\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m \u001b[43mevaluate_answer_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_answer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf1_score\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[106], line 7\u001b[0m, in \u001b[0;36mevaluate_answer_model\u001b[1;34m(dataset, eval_fn)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m dataset:\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(item)\n\u001b[1;32m----> 7\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43manswer_question\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcontexte\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitem\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mquestion\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(output)\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[103], line 12\u001b[0m, in \u001b[0;36manswer_question\u001b[1;34m(question, context, topN)\u001b[0m\n\u001b[0;32m      9\u001b[0m inputs \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mencode_plus(question, context, add_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)    \n\u001b[0;32m     10\u001b[0m input_ids \u001b[38;5;241m=\u001b[39m inputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist()[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m---> 12\u001b[0m model_out \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_answer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m answer_start_scores \u001b[38;5;241m=\u001b[39m model_out[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstart_logits\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     15\u001b[0m answer_end_scores \u001b[38;5;241m=\u001b[39m model_out[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend_logits\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\models\\bert\\modeling_bert.py:1848\u001b[0m, in \u001b[0;36mBertForQuestionAnswering.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, start_positions, end_positions, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1836\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1837\u001b[0m \u001b[38;5;124;03mstart_positions (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[0;32m   1838\u001b[0m \u001b[38;5;124;03m    Labels for position (index) of the start of the labelled span for computing the token classification loss.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1844\u001b[0m \u001b[38;5;124;03m    are not taken into account for computing the loss.\u001b[39;00m\n\u001b[0;32m   1845\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1846\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m-> 1848\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1849\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1850\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1851\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1852\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1853\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1854\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1855\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1856\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1857\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1858\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1860\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1862\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mqa_outputs(sequence_output)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\models\\bert\\modeling_bert.py:1013\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1006\u001b[0m \u001b[38;5;66;03m# Prepare head mask if needed\u001b[39;00m\n\u001b[0;32m   1007\u001b[0m \u001b[38;5;66;03m# 1.0 in head_mask indicate we keep the head\u001b[39;00m\n\u001b[0;32m   1008\u001b[0m \u001b[38;5;66;03m# attention_probs has shape bsz x n_heads x N x N\u001b[39;00m\n\u001b[0;32m   1009\u001b[0m \u001b[38;5;66;03m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001b[39;00m\n\u001b[0;32m   1010\u001b[0m \u001b[38;5;66;03m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001b[39;00m\n\u001b[0;32m   1011\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m-> 1013\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membeddings\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1014\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1015\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1016\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1017\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1018\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1019\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1020\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(\n\u001b[0;32m   1021\u001b[0m     embedding_output,\n\u001b[0;32m   1022\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mextended_attention_mask,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1030\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39mreturn_dict,\n\u001b[0;32m   1031\u001b[0m )\n\u001b[0;32m   1032\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\models\\bert\\modeling_bert.py:236\u001b[0m, in \u001b[0;36mBertEmbeddings.forward\u001b[1;34m(self, input_ids, token_type_ids, position_ids, inputs_embeds, past_key_values_length)\u001b[0m\n\u001b[0;32m    234\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mposition_embedding_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mabsolute\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    235\u001b[0m     position_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mposition_embeddings(position_ids)\n\u001b[1;32m--> 236\u001b[0m     \u001b[43membeddings\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mposition_embeddings\u001b[49m\n\u001b[0;32m    237\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mLayerNorm(embeddings)\n\u001b[0;32m    238\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(embeddings)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (847) must match the size of tensor b (512) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "#Evaluate the answer model\n",
    "\n",
    "def evaluate_answer_model(dataset, eval_fn):\n",
    "    for item in dataset:\n",
    "\n",
    "        print(item)\n",
    "        output = answer_question(item['contexte'], item['question'])\n",
    "\n",
    "        print(output)\n",
    "        break\n",
    "\n",
    "evaluate_answer_model(dataset_answer, f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46fa5340",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3fdd2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a19c165",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
